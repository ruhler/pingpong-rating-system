\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{pgfplots}

\begin{document}
\title{A Ping Pong Rating System}
\author{Richard Uhler}
\maketitle

\section{Introduction}
This document describes a ping pong rating system for rating players in a
local league. The format of the league is that every month participating
players are grouped with approximately four other players to play against. The
ratings are used to choose the groups; players are grouped with other players
of a similar level.

We assume that the large majority of players are amateur, without any prior
ping pong rating and not competing nationally nor otherwise outside of the
local league. In total we expect not more than a few hundred distinct players
to ever participate in the league. Individual players will play around four
matches a month, and there will not be more than around one hundred players
participating in any single month.

The primary goal of the rating system is to quickly establish a decent rank
order of players used to select the groups each month. Secondary goals of the
rating system are for the benefit and enjoyment of the players themselves:
\begin{itemize}
  \item A player should have a sense of how likely they are to win a match
    against another player by their ratings.
  \item For the most part, players should have unique ratings so that you can
    tell the difference between any two players.
  \item It is easy for players to remember and share their ratings with other
    players.
  \item Players are motivated to play more games rather than less games.
\end{itemize}

In a nutshell, we assume players have ratings such that the probability
of a player winning a match against another player is a logistics function of
the difference in their player ratings and that ratings are normally
distributed. We then estimate player ratings as those ratings that maximize
the likelihood of the observed match results. Finally, we scale the estimated
player ratings so that they are likely to be in the range from 0 to 2000, with
the average player having a rating of 1000.

\section{The Logistics Function}
Assume players have ratings such that the probability of a player winning a
match against another player is a logistics function of the difference in
their player ratings.

For each player $i$, we assign a rating $x_i \in \mathbb{R}$. We assign the
ratings for each player so that, given any two players $i$ and $j$ with
ratings $x_i$ and $x_j$, the probability that player $i$ beats player $j$ in a
match is:
\begin{equation}
  f(x_i, x_j) = \frac{1}{1 + e^{-\kappa(x_i - x_j)}}
\end{equation}

\begin{figure}
  \caption{The logistics function}
  \label{fig:logistics}
 \begin{tikzpicture}
   \begin{axis}[grid=major, xmin=-8, xmax=8, axis x line=bottom,
         xtick={0}, ytick={0,.5,1}, ymax=1, axis y line=middle,
         xticklabels={},
         width=\textwidth, height=\axisdefaultheight, 
         xlabel={$(x_i-x_j)$}, ylabel={$f(x_i, x_j)$},
       ]
      \addplot[mark=none, samples=100, domain=-8:8, ]
         (x,{1/(1+exp(-x))});
     \end{axis}
 \end{tikzpicture}
 \end{figure}

The function $f(x_i, x_j)$ is a logistics function in $(x_i - x_j)$, the
difference between the two players' ratings. The graph of the logistics
function is shown in figure \ref{fig:logistics}. The logistics function is
good to use for our purposes because it behaves as we would hope and expect
for the probability of a player winning a match against another player. In
particular:
\begin{itemize}
  \item The range of the function is $f(x_i, x_j) \in [0, 1]$, consistent with
    it being a measure of probability.

  \item For two players with the same rating, each player is as likely to win
    the match: $f(x, x) = \frac{1}{1 + e^0} = 0.5$.

  \item More generally, the probability of player $i$ losing against player
    $j$ is the same as the probability of player $j$ winning against player
    $i$:
    \begin{align*}
      1 - f(x_i, x_j) &= 1 - \frac{1}{1 + e^{-\kappa(x_i - x_j)}} = \frac{(1 + e^{-\kappa(x_i - x_j)}) - 1}{1 + e^{-\kappa(x_i - x_j)}} \\
                      &= \frac{e^{-\kappa(x_i - x_j)}}{1 + e^{-\kappa(x_i - x_j)}} = \frac{1}{e^{\kappa(x_i - x_j)} + 1} = f(x_j, x_i)
    \end{align*}

  \item The greater the rating $x_i$ of player $i$ is relative to the rating
    $x_j$ of player $j$, the more likely player $i$ is of beating player $j$.
    This is most easily confirmed by the upward sloping of the graph in figure
    \ref{fig:logistics}.

  \item If player $i$ is rated significantly higher than player $j$, player
    $i$ will beat player $j$ with almost certainty.
    \begin{equation*}
      \lim_{x_i \to \infty} f(x_i, x_j) = \frac{1}{1 + e^{-\infty}} = 1
    \end{equation*}
\end{itemize}

Note that the probability of a player winning a match against another player
depends only on the players' relative ratings, not the absolute value of their
ratings. We could, if we like, shift all of the ratings by any constant $c$
without impacting the likely match outcomes:
\begin{equation*}
  f(x_i - c, x_j - c) =
  \frac{1}{1 + e^{-\kappa(x_i - c - x_j + c)}} =
  \frac{1}{1 + e^{-\kappa(x_i - x_j)}} = f(x_i, x_j)
\end{equation*}

We will take advantage of this fact later to assign a particular absolute
rating to the average player.

We can scale the ratings by some constant factor $a$ without impacting the
likely match outcomes as long as we scale the factor $\kappa$ used in the
logistics function appropriately:
\begin{equation*}
  f_\kappa(a x_i, a x_j) =
  \frac{1}{1 + e^{-\kappa(a x_i - a x_j)}} =
  \frac{1}{1 + e^{-a \kappa(x_i - x_j)}} = f_{a \kappa}(x_i, x_j)
\end{equation*}

In particular, if we choose to scale up the ratings by some constant factor
$a$, we need to scale down the factor $\kappa$ in the logistics function to
get the same likely match outcomes.

\section{Normal Distribution of Ratings}
\begin{figure}
  \caption{A normal distribution}
  \label{fig:normal}
 \begin{tikzpicture}
   \begin{axis}[grid=none, xmin=-5, xmax=5,
         xtick={}, ytick={}, ymax=0.5,
         xticklabels={}, yticklabels={},
         width=\textwidth, height=\axisdefaultheight, 
         xlabel={$x_i$}, ylabel={$g(x_i)$},
       ]
      \addplot[mark=none, samples=100, domain=-5:5, ]
      (x,{exp(-x*x)/sqrt(2*pi)});
     \end{axis}
 \end{tikzpicture}
 \end{figure}
Imagine there are only two players $i$ and $j$, and that these players have
played a single match in which player $i$ beat player $j$. What ratings $x_i$
and $x_j$ should we infer for the players?

We have observed that player $i$ beat player $j$ in $100\%$ of the matches
they played. The best choice for $x_i$ and $x_j$ that makes $f(x_i, x_j) = 1$
is to set $x_i$ and $x_j$ as far apart as possible. In other words,
$x_i = \infty$ and $x_j = -\infty$. But this is absurd. Surely player $i$
isn't an infinitely good player because they won a single match against player
$j$. It probably wouldn't be hard to find some other player $\kappa$ who can beat
player $j$, meaning our estimate of $x_i = \infty$ is not very good.

More realistically, player ratings will tend to be independently and
identically distributed in some way, perhaps as a function of how much time
the player has spent playing ping pong. If this is the case, then we expect to
find the distribution of ratings for all players to follow a normal
distribution, such as the one pictured in figure \ref{fig:normal}. The
probability of a player $i$ having a rating $x_i$ is:
\begin{equation}
  g(x_i) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x_i - \mu)^2}{2 \sigma^2}}
\end{equation}

Where $\mu$ is the mean player rating and $\sigma^2$ is the variance in player
ratings.

Assuming reasonable values for $\mu$ and $\sigma^2$, there is almost no chance
that player $i$ has rating $x_i = \infty$. By taking the normal distribution
of player ratings into account, we can make much more reasonable estimates for
player ratings. After all, even if players $i$ and $j$ are evenly matched,
it's not that unlikely for player $i$ to have beaten player $j$ in a single
match.

We already saw that we are free to shift the player ratings by an
arbitrary constant $c$ without effecting the likely match outcomes, so we can
choose $\mu$ to be whatever we like. For simplicity to start, we'll choose
$\mu = 0$. We are also allowed to scale player ratings by an arbitrary factor
$a$, so we have the option to choose any value for $\sigma^2$ that we like,
but only if we also adjust the $\kappa$ factor in the logistics function
appropriately. While we are free to pick either one of $\sigma^2$ or $\kappa$ to be
whatever we like, the product $\sigma^2 \kappa^2$ must remain fixed.

The constant $S = \sigma^2 \kappa^2$ is an intrinsic property of the world,
representing how large the range of ping pong player skill levels is. For now
we will leave the logistics function and normal distribution generic in $\kappa$
and $\sigma^2$ rather than worry about how to determine the constant $S$.

\section{Raw Rating Definition}
Players' ratings are chosen to be those ratings that maximize the likehood of
the observed match results and player ratings. Assuming a set of players
$i \in P$ and (possibly duplicate) match results
$(i, j) \in M$, where $(i, j)$ means the player $i$ beat the player
$j$ in a single match, we choose $x_i$ to maximize:
\begin{equation}
  L(x, P, M) = \prod_{i \in P} g(x_i)  \prod_{(i, j) \in M} f(x_i, x_j)
\end{equation}

To solve for the values of $x_i$ that maximize $L(x, P, M)$,
we take partial derivitives of $L$ and set them equal to $0$. For a particular
$x_k$ we have:

\begin{equation*}
  \frac{\partial}{\partial x_k} \left[ \prod_{i \in P} g(x_i)  \prod_{(i, j) \in M} f(x_i, x_j) \right] = 0
\end{equation*}

Pulling out the factors that don't depend on $x_k$, we have:
\begin{equation} \label{eq:partialproduct}
  \frac{\partial}{\partial x_k} \left[ g(x_k)
      \prod_{(k, j) \in M} f(x_k, x_j)
    \prod_{(j, k) \in M} f(x_j, x_k) \right]
      = 0
\end{equation}

This equation takes the form
\begin{equation*}
  \frac{d}{dx}[a(x) b(x) c(x) \cdots] = 0
\end{equation*}

By the product rule this is:
\begin{equation*}
    a'(x) b(x) c(x) \cdots
  + a(x) b'(x) c(x) \cdots
  + a(x) b(x) c'(x) \cdots + \cdots = 0
\end{equation*}

Factoring out the common product:
\begin{equation*}
  (a(x) b(x) c(x) \cdots) (
      \frac{a'(x)}{a(x)}
    + \frac{b'(x)}{b(x)}
    + \frac{c'(x)}{c(x)}
    + \cdots) = 0
\end{equation*}

Assuming none of $a(x)$, $b(x)$, $c(x)$, $\ldots$ are 0 in the region of
interest, this reduces to:
\begin{equation*}
      \frac{a'(x)}{a(x)}
    + \frac{b'(x)}{b(x)}
    + \frac{c'(x)}{c(x)}
    + \ldots = 0
\end{equation*}

In equation \ref{eq:partialproduct}, there are three types of terms: $g(x_k)$, 
$f(x_k, x_j)$, and $f(x_j, x_k)$. Let's consider each in turn.

\begin{equation*}
  g'(x_k) = \frac{d}{d x_k} \left[ \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-x_k^2}{\sigma^2}} \right]
  = (-\frac{2 x_k}{2 \sigma^2}) \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x_k - \mu)^2}{\sigma^2}}
    = -\frac{x_k}{\sigma^2} g(x_k)
  \end{equation*}
\begin{equation*}
  \frac{g'(x_k)}{g(x_k)} = -\frac{x_k}{\sigma^2}
\end{equation*}

\begin{align*}
  f'(x_k, x_j) &= \frac{\partial}{\partial x_k} \left[\frac{1}{1 + e^{-\kappa(x_i - x_j)}}\right] \\
               &= \frac{\kappa e^{-\kappa(x_k - x_j)}}{(1 + e^{-\kappa(x_k - x_j)})^2}
  = \frac{\kappa e^{-\kappa(x_k - x_j)}}{1 + e^{-\kappa(x_k - x_j)}} f(x_k, x_j)
\end{align*}
\begin{equation*}
  \frac{f'(x_k, x_j)}{f(x_k, x_j)}
  = \frac{\kappa e^{-\kappa(x_k - x_j)}}{1 + e^{-\kappa(x_k - x_j)}}
  = \frac{\kappa}{e^{\kappa(x_k - x_j)} + 1} = \kappa f(x_j, x_k)
\end{equation*}

The case for $f(x_j, x_k)$ is the same as $f(x_k, x_j)$ with the opposite
sign.

Combining all of these together, we have from equation \ref{eq:partialproduct}:
\begin{equation*}
  - \frac{x_k}{\sigma^2}
  + \sum_{(k, j) \in M} \kappa f(x_j, x_k)
  - \sum_{(j, k) \in M} \kappa f(x_k, x_j) = 0
\end{equation*}

Because we know $f(x_j, x_k) = 1 - f(x_k, x_j)$, we can reorganize the sum:
\begin{align*}
  &- \frac{x_k}{\sigma^2}
  + \sum_{(k, j) \in M} \kappa (1 - f(x_k, x_h))
  - \sum_{(j, k) \in M} \kappa f(x_k, x_j) \\
  = &- \frac{x_k}{\sigma^2}
  + \kappa \sum_{(k, j) \in M} 1
  - \kappa \left(\sum_{(j, k) \in M} f(x_k, x_j) + \sum_{(k, j) \in M} f(x_k, x_j)\right) 
\end{align*}

If we let $W_k$ be the total number of matches won by player $k$, and $M_{k,j}$
be the total number of matches played between player $k$ and player $j$, then
the equation becomes:
\begin{equation*}
  - \frac{x_k}{\sigma^2} + \kappa W_k - \kappa \sum_{j \in P} M_{k,j} f(x_k, x_j) = 0
\end{equation*}

Dividing by the product $M_k \kappa$, where $M_k$ is the total number of matches
played by player $k$, we have:
\begin{equation*}
  - \frac{x_k}{M_k \kappa \sigma^2} + w_k - \sum_{j \in P} m_{k, j} f(x_k, x_j) = 0
\end{equation*}

Where $w_k$ is the fraction of matches played by player $k$ that player $k$
won, and $m_{k, j}$ is the fraction of matches played by player $k$ against
player $j$. Rearranging, we get:
\begin{equation}
  w_k = \frac{x_k}{M_k \kappa \sigma^2} + \sum_{j \in P} m_{k, j} f(x_k, x_j)
\end{equation}

We can interpret this equation as saying we want to choose $x_k$ so that the
observed fraction of matches won by player $k$, $w_k$, is the weighted sum of the
win fraction predicted by the logistics function plus an additional error term
to correct for observed results that arise from the player not having played
many matches. The more matches the player plays, the smaller this additional
error term is.

This equation does not have an easy analytical solution, but we can easily use
numeric methods to compute the ratings for all players. We can approximate the
solution to this equation by minimizing the squared difference of both sides
of the equation. We can approximate the solution for all players by minimizing
the sum of the squared differences for every player:

\begin{align*}
    &(w_0 - (\frac{x_0}{M_0 \kappa \sigma^2} + \sum_{j \in P} m_{0, j} f(x_0, x_j)))^2 \\
  + &(w_1 - (\frac{x_1}{M_1 \kappa \sigma^2} + \sum_{j \in P} m_{1, j} f(x_1, x_j)))^2 \\
  + &(w_2 - (\frac{x_2}{M_2 \kappa \sigma^2} + \sum_{j \in P} m_{2, j} f(x_2, x_j)))^2 + \ldots
\end{align*}

For example, this expression can be minimized by simple gradient descent
algorithm.

Notice that as the number of matches each player has played goes up, the
parameters $\kappa$ and $\sigma^2$ make less and less of a difference in the
estimated player ratings. Given that is the case, we will simply take $\kappa = 1$
and $\sigma^2 = 1$, which gives $S = \kappa^2 \sigma^2 = 1$ as the intrinsic
constant\footnote{Statistics compiled on the distribution of USATT ratings
  suggest $S$ is somewhere between 1 and 100 in practice.}.

\section{Normalized Ratings}
The raw ratings described in the previous section are good for rank ordering
players for the purposes of selecting groups, but they are not very convenient
for the players to refer to, because they have fractional parts and can be
positive or negative. To make it easier to refer to the player ratings, we
scale and shift the ratings so that the players can have a simple positive
integer rating to remember and share. Experience with USATT ratings shows that
it is easy to remember and share ratings in the range from 0 to 3000. A
smaller range of ratings, such as 0 to 100, would likely not provide as much
resolution between different players as is desired. For this reason we choose
to scale the ratings so that the average player has rating 1000 with standard
deviation of 250, which makes it extremely unlikely that any player will end
up with a negative rating (or, as a consequence, a rating over 2000).

\end{document}
